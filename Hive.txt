> HIVE: 
	- It is a data warehouse for Hadoop. 
	- It points to heterogenous form of data residing on HDFS and retrives it in the form of schema. 
	- It is a folder residing on HDFS.
	- The data stored in HIVE is in unstructured format, but if user want to see the data, it is visible in tabular format.
	- Uses HiveQL as scripting language.
	
> Cloudera Path of HIVE: /user/hive/warehouse/
> Hortonworks Path of HIVE: /app/hive/warehouse/

# ROW FORMAT DELIMITED works on on Text(.txt) file.

> Types of tables: 
	- Managed: Data & Metadata both are deleted while dropping the table.
	- External: Only Data gets deleted and Metadata remains as it is.
	
# LOCATION: stores the file in the specified location.

> Metadata(Structure of the table like datatype of each field, database owner, location, etc.) is stored in MetastoreDB.
# describe formatted <table_name>: Use to display metadata of the table.


> Dynamic Partition: Used to distributed the data on the basis of a column which will act as a key.
	eg. suppose we partitioned a table by COUNTRY column, HIVE will extract unique values in the country column and it will group the records based in countries and stores it the seperate files.
		# create table dynamic_table(id string,name string) partitioned by (country string) row format delimited fields terminated by '\t';
		- /user/hive/warehouse/dynamic_table/country=India
		- /user/hive/warehouse/dynamic_table/country=US
		- /user/hive/warehouse/dynamic_table/country=UK

> Skewed Table:
	
# distributed by :
	- A single reducer will be allocated to the records with same value.
	eg. No.	Age	Name
		1	10	abc
		2	15	aaa
		3	25	bbb
		4	15	ccc
		5	25	ddd
	- Persons with age 15 and 25 with be sent with each reducers respectively. (1 for 15 and 1 for 25)
		
> JOIN:
	1. Shuffle Join: Joins keys are shuffled using MapReduce, and joins are performed on Reduce side.
	2. Map(Broadcast) Join: Small tables(tables which can be fitted into the distributed cache) are loaded into memory in all nodes. Scans for bigger table and determine if the required records are available in smaller table.
	3. Sort-Merge-Bucket Join: Requires bucketed tables. Joins with the help of co-relation keys.
	
> Ngram: 
	- Extracting the collection of 'n' no. of words.
	- Use to find frequency of words.(Highest frequent words are shown on the TOP)
# select explode(context_ngrams(sentences(line),array(null,"the",null),20)) as result from constitution;

> SERDE: Converts the binary form of data from .avro file and put it in table by converting it to the text format.

> Windowing functionality: (Over Clause)

> Beeline: JDBC/ODBC based CLI.
